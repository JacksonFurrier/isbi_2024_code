{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51eb4d33-824e-414e-b3b9-c537261ac00c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "from typing import Tuple\n",
    "\n",
    "import yaml\n",
    "from tqdm.notebook import tqdm\n",
    "import nrrd\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torchio as tio\n",
    "import torch\n",
    "from unet import UNet\n",
    "\n",
    "from skimage.metrics import structural_similarity as ssim\n",
    "from skimage.util import montage\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "from scipy.spatial.transform import Rotation as R\n",
    "\n",
    "from src.tools.recon.projector import forward_projector, backward_projector\n",
    "from src.tools.manip.manip import normalize_volume\n",
    "\n",
    "# data fetching and handling\n",
    "from data.check_database import load_remote_data\n",
    "from data.fetch_data import fetch_data\n",
    "from src.tools.data.loadvolumes import LoadVolumes\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# CMF algorithm shape prior enhancement \n",
    "from src.algs.arm import lv_indicator\n",
    "from src.tools.cmf.cmf_shape_prior import cmf_shape_prior\n",
    "from src.tools.kde.nonlinear_shape_prior import nonlinear_shape_prior, nonlinear_shape_prior_grad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86699084",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# copied from supervised_learning.py\n",
    "\n",
    "path_experiment_conf = Path().resolve().joinpath('../../exp/supervised_training_best.yaml')\n",
    "\n",
    "with open(path_experiment_conf, 'r') as file:\n",
    "    conf = yaml.load(file, Loader=yaml.Loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d9cadc8",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "conf"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Data types and set-up for loading the data from a remote html server"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "53b2e188b7ca1135"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "lv_model_volume = None\n",
    "lv_model_frames = None\n",
    "lv_motion_frames = None\n",
    "lv_volume = None\n",
    "\n",
    "volume = np.zeros([64, 64, 64])\n",
    "params = dict(a=1, c=2, sigma=-1)\n",
    "transform_params = [np.eye(3, 3), [16, 16, 0], 1.5]\n",
    "\n",
    "recon_mode = 'basic'\n",
    "fprojector = forward_projector(recon_mode)\n",
    "\n",
    "lv_model_volume = lv_indicator(volume, params, transform_params)\n",
    "lv_model_frames = fprojector(lv_model_volume)\n",
    "lv_motion_frames = np.zeros(lv_model_frames.shape)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "bcdcb7ed57cd742a"
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Data fetching from remote server "
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "3de93d707dd45e52"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "dicom_loader = LoadVolumes()\n",
    "\n",
    "# initialize data fetching from remote, configuration is in data/remote.yml\n",
    "data_loaded = False\n",
    "url, datasets = load_remote_data()\n",
    "\n",
    "# fetch specific patient data\n",
    "dicom_name = datasets['raw/']['turkey_par/'][10]\n",
    "data_url = url + '/raw/' + 'turkey_par/' + dicom_name\n",
    "\n",
    "# fetch the data from remote\n",
    "data = fetch_data(data_url)\n",
    "\n",
    "# load data with the dicom loader\n",
    "frames, data_loaded = dicom_loader.LoadSinglePatient(data)\n",
    "\n",
    "# normalizing the frame values\n",
    "normalize_volume(frames)\n",
    "frames = frames + 1\n",
    "\n",
    "assert (data_loaded)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "f5d437ca10d7d14a"
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Load model and check devices"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "251385abbeda9040"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae223d52-65dd-4d00-a380-89d2dea79fbc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# copied from supervised_learning.py\n",
    "\n",
    "def get_model_and_optimizer(\n",
    "    config: dict,\n",
    "    device: str\n",
    ") -> Tuple[torch.nn.Module, torch.optim.Optimizer]:\n",
    "    \"\"\"\n",
    "\n",
    "    :param config:\n",
    "    :param device:\n",
    "    :return:\n",
    "    \"\"\"\n",
    "    model = UNet(\n",
    "        in_channels=1,\n",
    "        out_classes=2,\n",
    "        dimensions=3,\n",
    "        upsampling_type='linear',\n",
    "        padding=True,\n",
    "        activation='PReLU',\n",
    "        **config['model']['UNet']\n",
    "    ).to(device)\n",
    "\n",
    "    optimizer = torch.optim.AdamW(\n",
    "        model.parameters(),\n",
    "        lr=config['optimizer']['learning_rate']\n",
    "    )\n",
    "\n",
    "    return model, optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cbd513b4-9a33-45ba-bc6f-fc3209b60c91",
   "metadata": {},
   "outputs": [],
   "source": [
    "path_saved_models = Path().resolve().parent.joinpath('saved_models')\n",
    "\n",
    "# supervised fine-tuning experiment name\n",
    "experiment = conf['experiment_name']\n",
    "path_weights = path_saved_models.joinpath(f\"{experiment}.pth\")\n",
    "\n",
    "weights = torch.load(path_weights)['weights']\n",
    "\n",
    "device = torch.device('cuda') if torch.cuda.is_available() else 'cpu'\n",
    "\n",
    "model, optimizer = get_model_and_optimizer(conf, device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ac98bec-17d5-4a02-a3e1-8bd1603cfc39",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.load_state_dict(weights)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83c3ad0e-c7ac-496a-aa21-d0fe5379274d",
   "metadata": {},
   "source": [
    "# Segmentation with trained model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9ac7d10-d6c6-408a-9ab6-787d383e736c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_image(path):\n",
    "    \n",
    "    data, header = nrrd.read(path)\n",
    "    data = data.astype(np.float32)\n",
    "    affine = np.eye(4)\n",
    "    \n",
    "    return data, affine\n",
    "\n",
    "\n",
    "def prepare_batch(batch, device):\n",
    "    \n",
    "    inputs = batch['spect'][tio.DATA].to(device)\n",
    "    targets = batch['left_ventricle'][tio.DATA].to(device)\n",
    "    \n",
    "    return inputs, targets\n",
    "\n",
    "\n",
    "class Visualizer:\n",
    "    \n",
    "    def montage_nrrd(self, image):\n",
    "        if len(image.shape) > 2:\n",
    "            return montage(image)\n",
    "        else:\n",
    "            warnings.warn('Pass a 3D volume', RuntimeWarning)\n",
    "            return image\n",
    "        \n",
    "    def visualize(self, image, mask=None):\n",
    "        \n",
    "        if mask is None:\n",
    "            fig, axes = plt.subplots(1, 1, figsize=(10, 10))\n",
    "            axes.imshow(self.montage_nrrd(image))\n",
    "            axes.set_axis_off()\n",
    "        else:\n",
    "            fig, axes = plt.subplots(1, 2, figsize=(40, 40))\n",
    "        \n",
    "            for i, data in enumerate([image, mask]):\n",
    "                axes[i].imshow(self.montage_nrrd(data))\n",
    "                axes[i].set_axis_off()\n",
    " \n",
    "\n",
    "def compute_metrics(prediction, target):\n",
    "    epsilon=1e-9\n",
    "    \n",
    "    pred = prediction.argmax(dim=1)\n",
    "    targ = target.argmax(dim=1)\n",
    "    p1 = 1 - pred\n",
    "    g1 = 1 - targ\n",
    "    \n",
    "    tp = (targ * pred).sum(dim=(1, 2, 3))\n",
    "    fp = (pred * g1).sum(dim=(1, 2, 3))\n",
    "    fn = (p1 * targ).sum(dim=(1, 2, 3))\n",
    "    \n",
    "    precision = (tp / (tp + fp)).mean().cpu().numpy().item()\n",
    "    recall = (tp / (tp + fn)).mean().cpu().numpy().item()\n",
    "    iou = (tp / (tp + fp + fn)).mean().cpu().numpy().item()\n",
    "    dice_score = ((2 * tp) / (2 * tp + fp + fn + epsilon)).mean().cpu().numpy().item()\n",
    "    #ssim_score = pytorch_ssim.ssim(target, prediction).mean().cpu().numpy().item()\n",
    "    \n",
    "    return precision, recall, iou, dice_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b371a506-e280-418f-98f5-c4c01f2f7a08",
   "metadata": {},
   "outputs": [],
   "source": [
    "path_data = Path().resolve().parent.joinpath('../data')\n",
    "path_eda = path_data.joinpath('eda')\n",
    "path_segmentation = path_data.joinpath('segmentation_xyz')\n",
    "\n",
    "df = pd.read_csv(path_eda.joinpath('spect_data.csv'))\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0b948ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "subjects = []\n",
    "target_shape = (128, 128, 32)\n",
    "\n",
    "transform_pipeline = tio.Compose([\n",
    "    tio.CropOrPad(target_shape=target_shape, mask_name=\"left_ventricle\"),\n",
    "    tio.ZNormalization(),\n",
    "    tio.OneHot()\n",
    "])\n",
    "\n",
    "segmentations = list(df.loc[(df['mask'].notnull()), ['image', 'mask']].to_records(index=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3bdaaee",
   "metadata": {},
   "outputs": [],
   "source": [
    "smap = map(\n",
    "    lambda x: (\n",
    "        path_segmentation.joinpath(x[0]),\n",
    "        path_segmentation.joinpath(x[1])\n",
    "    ), \n",
    "    segmentations\n",
    ")\n",
    "\n",
    "segmentations = list(smap)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f63c2bca",
   "metadata": {},
   "outputs": [],
   "source": [
    "for image_path, label_path in segmentations:\n",
    "\n",
    "    subject = tio.Subject(\n",
    "        spect=tio.ScalarImage(image_path, reader=load_image),\n",
    "        left_ventricle=tio.LabelMap(label_path, reader=load_image)\n",
    "    )\n",
    "    subjects.append(subject)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11ffb4ba-0ecb-42cc-99d9-64ec1ad29d36",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = tio.SubjectsDataset(subjects, transform=transform_pipeline)\n",
    "print(f\"Dataset size: {len(dataset)} subjects\")\n",
    "\n",
    "data_loader = torch.utils.data.DataLoader(\n",
    "    dataset,\n",
    "    batch_size=2,\n",
    "    shuffle=False,\n",
    "    num_workers=0,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d9d5cd8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_ssim_score(label_np, pred_np):\n",
    "    ssim_score = ssim(\n",
    "        label_np,\n",
    "        pred_np,\n",
    "        data_range=pred_np.max() - pred_np.min(),\n",
    "        channel_axis=True\n",
    "    )\n",
    "    return ssim_score\n",
    "\n",
    "def calculate_specificity_recall_precision(label_np, pred_np):\n",
    "    label_flat = label_np.flatten()\n",
    "    pred_flat = (pred_np > 0.5).astype(int).flatten()\n",
    "    tn, fp, fn, tp = confusion_matrix(label_flat, pred_flat).ravel()\n",
    "    specificity = tn / (tn + fp)\n",
    "    recall = tp / (tp + fn)\n",
    "    precision = tp / (tp + fp)\n",
    "    return specificity, recall, precision"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e79c57c-4008-4218-abba-8f5d02509dff",
   "metadata": {},
   "outputs": [],
   "source": [
    "FOREGROUND = 1\n",
    "vis = Visualizer()\n",
    "\n",
    "model.eval()\n",
    "\n",
    "num_samples = 0\n",
    "specificity_list = []\n",
    "recall_list = []\n",
    "precision_list = []\n",
    "\n",
    "\n",
    "for batch_idx, batch in enumerate(tqdm(data_loader)):\n",
    "\n",
    "    inputs, targets = prepare_batch(batch, device)\n",
    "    \n",
    "    with torch.no_grad():\n",
    "\n",
    "        predictions = model(inputs).softmax(dim=1)\n",
    "        probabilities = predictions[:, FOREGROUND:].cpu()\n",
    "    \n",
    "\n",
    "    for i in range(len(batch['spect'][tio.DATA])):\n",
    "    \n",
    "        spect = batch['spect'][tio.DATA][i].permute(3, 0, 1, 2)\n",
    "        label = batch['left_ventricle'][tio.DATA][i][1:, ...].permute(3, 0, 1, 2)\n",
    "        pred = probabilities[i].permute(3, 0, 1, 2)\n",
    "        \n",
    "        # vis.visualize(\n",
    "        #     np.squeeze(label.permute(1,0,2,3).numpy(), axis=0),\n",
    "        #     np.squeeze(pred.permute(1,0,2,3).numpy(), axis=0)\n",
    "        # )\n",
    "        \n",
    "        label_np = label.squeeze().permute(1, 2, 0).numpy()\n",
    "        pred_np = pred.squeeze().permute(1, 2, 0).numpy()\n",
    "        \n",
    "        num_samples += 1\n",
    "        \n",
    "        specificity, recall, precision = calculate_specificity_recall_precision(label_np, pred_np)\n",
    "        specificity_list.append(1 - specificity)\n",
    "        recall_list.append(recall)\n",
    "        precision_list.append(precision)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37c966b1-142f-4b23-85af-aa2f4881c782",
   "metadata": {},
   "outputs": [],
   "source": [
    "precision, recall, iou, dice = compute_metrics(predictions, targets)\n",
    "\n",
    "print(f\"Precision: {precision:.4f}\")\n",
    "print(f\"Recall: {recall:.4f}\")\n",
    "print(f\"IoU: {iou:.4f}\")\n",
    "print(f\"Dice score: {dice:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "predictions.shape"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "554a467dd123158a"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "pred = predictions.argmax(dim=1) # predictions\n",
    "target = targets.argmax(dim=1) # labels\n",
    "lv_spect = batch['spect'][tio.DATA][0]\n",
    "%matplotlib notebook\n",
    "plt.imshow(lv_spect[0, :, :, 16].cpu().numpy())"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "7bd4623809e1bf88"
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Running shape prior enhanced CMF on predictions"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "12c59e39b0a4c266"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "num_frames, width, height = frames.shape\n",
    "\n",
    "bprojectpor = backward_projector()\n",
    "lv_volume = bprojectpor(frames)\n",
    "\n",
    "# lv_volume = np.random.rand(64, 64, 64)\n",
    "normalize_volume(lv_volume)\n",
    "\n",
    "num_prior = 9\n",
    "shape_priors = np.zeros([num_prior, *lv_volume.shape])\n",
    "\n",
    "wall_thickness = np.random.uniform(0.3, 1.0, num_prior)\n",
    "rot_angles = np.random.uniform(0, 2 * np.pi, num_prior)\n",
    "curvature = np.random.uniform(1.5, 3, num_prior)\n",
    "sigmas = np.random.uniform(-0.5, -1, num_prior)\n",
    "\n",
    "for i in range(num_prior):\n",
    "    volume = np.zeros([*lv_volume.shape])\n",
    "    params = dict(a=wall_thickness[i], c=curvature[i], sigma=sigmas[i])\n",
    "    rot_mx = R.from_quat([0, 0, np.sin(rot_angles[i]), np.cos(rot_angles[i])])\n",
    "\n",
    "    transform_params = [np.eye(3, 3), [16, 16, 0], 1.5]\n",
    "    shape_priors[i] = lv_indicator(volume, params, transform_params, a_plot=False)\n",
    "\n",
    "    recon_mode = 'basic'\n",
    "    fprojector = forward_projector(recon_mode)\n",
    "\n",
    "    frames = fprojector(shape_priors[i])"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "51bebdd8dfc2ec53"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# u_init = pred[0]\n",
    "# lv_volume = lv_spect[0]\n",
    "# \n",
    "# sigma_inv, mean_shape, dec_faces = nonlinear_shape_prior(shape_priors, 1.0, 52)\n",
    "# \n",
    "# opt_params = dict(num_iter=4, err_bound=0, gamma=1e-1, steps=1e-1)\n",
    "# cmf_params = dict(par_lambda=10, u_init=u_init.cpu().to(torch.float32) ,par_nu=1, c_zero=0.1, c_one=0.8, b_zero=0.1, b_one=0.7, sigma_inv=sigma_inv, mean_shape=mean_shape, faces=dec_faces)\n",
    "# lam, err_iter, num_iter = cmf_shape_prior(a_volume=lv_volume.cpu(), a_opt_params=opt_params, a_algo_params=cmf_params)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "916d0b5d22399497"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09b2dbdb",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axs = plt.subplots(1, 2, figsize=(12,5))\n",
    "\n",
    "roc_data1 = np.column_stack((specificity_list, recall_list))\n",
    "roc_data1 = roc_data1[roc_data1[:, 0].argsort()]\n",
    "roc_data2 = np.column_stack((recall_list, precision_list))\n",
    "roc_data2 = roc_data2[roc_data2[:, 0].argsort()]\n",
    "\n",
    "axs[0].plot(roc_data1[:, 0], roc_data1[:, 1])\n",
    "axs[0].set_xlabel('1 - Specificity')\n",
    "axs[0].set_ylabel('Recall')\n",
    "\n",
    "axs[1].plot(roc_data2[:, 0], roc_data2[:, 1])\n",
    "axs[1].set_xlabel('Recall')\n",
    "axs[1].set_ylabel('Precision')\n",
    "\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d97ab70d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.interpolate import interp1d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d3cd88e",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = np.linspace(0, 1, len(roc_data1[:,0]))\n",
    "y = roc_data1[:,1]\n",
    "\n",
    "prec_int = interp1d(x, y, \"cubic\")\n",
    "\n",
    "x_ = np.linspace(0, 1, 500)\n",
    "fig, axs = plt.subplots()\n",
    "axs.plot(x_, prec_int(x_))\n",
    "\n",
    "axs.spines['top'].set_visible(False)\n",
    "axs.spines['right'].set_visible(False)\n",
    "plt.ylabel(\"Recall\")\n",
    "plt.xlabel(\"1-Specificity\")\n",
    "# plt.savefig('roc_rec_spec.pdf')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb38b906-8ab1-40a4-b178-eaa12b190111",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch = next(iter(data_loader))\n",
    "\n",
    "inputs, targets = prepare_batch(batch, device)\n",
    "FIRST = 1\n",
    "FOREGROUND = 1\n",
    "\n",
    "with torch.no_grad():\n",
    "\n",
    "    probabilities = model(inputs).softmax(dim=1)[:, FOREGROUND:].cpu()\n",
    "\n",
    "affine = batch['spect'][tio.AFFINE][0].numpy()\n",
    "\n",
    "subject = tio.Subject(\n",
    "    spect=tio.ScalarImage(tensor=batch['spect'][tio.DATA][FIRST], affine=affine),\n",
    "    label=tio.LabelMap(tensor=batch['left_ventricle'][tio.DATA][FIRST], affine=affine),\n",
    "    predicted=tio.ScalarImage(tensor=probabilities[FIRST], affine=affine),\n",
    ")\n",
    "subject.plot(figsize=(9, 8), cmap_dict={'predicted': 'RdBu_r'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29d968f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "type(inputs)\n",
    "inputs.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Running CMF shape prior on hypoperfused hearts"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "31a779d366a106bf"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "path_images = [\n",
    "    \"/home/jackson/GIT/ELTE/papers/left_ventricle_segmentation/data/tc99_female_no_defect.nrrd\",\n",
    "    \"/home/jackson/GIT/ELTE/papers/left_ventricle_segmentation/data/tc99_inferior_perf_defect.nrrd\",\n",
    "    \"/home/jackson/GIT/ELTE/papers/left_ventricle_segmentation/data/tc99m_reversible_defect.nrrd\",\n",
    "    \"/home/jackson/GIT/ELTE/papers/left_ventricle_segmentation/data/tc99m_stable_perfusion_defect.nrrd\"\n",
    "]\n",
    "\n",
    "images = []\n",
    "\n",
    "# load images from local folder\n",
    "for path in path_images:\n",
    "    img, _ = load_image(path)\n",
    "    images.append(torch.from_numpy(img).to(device))\n",
    "\n",
    "# running the network on ill conditioned patients\n",
    "pred = []\n",
    "\n",
    "target_shape = (64, 64, 64)\n",
    "transform = tio.Compose([\n",
    "    tio.CropOrPad(target_shape=target_shape),\n",
    "    tio.ZNormalization(),\n",
    "    tio.OneHot()\n",
    "])\n",
    "\n",
    "subjects = []\n",
    "\n",
    "for path in path_images:\n",
    "    with torch.no_grad():\n",
    "        subject = tio.Subject(\n",
    "            lv_volume = tio.ScalarImage(path),\n",
    "            reader=load_image\n",
    "        )\n",
    "        subject.load()\n",
    "        transformed = transform(subject)\n",
    "        subjects.append(transformed)\n",
    "        \n",
    "        img_pred = model(transformed['lv_volume'][tio.DATA][None, ...].to(device)).softmax(dim=1)[:, FOREGROUND].cpu() # for debugging purpose\n",
    "        pred.append(img_pred)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "56e912ef2c519754"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "\n",
    "# run shape prior based CMF enhancement on predictions\n",
    "z_i, sigma_inv, L, V, sigma_ort, sigma, first_cplx, min_shape_face_count, mean_shape, mean_shape_face  = nonlinear_shape_prior(shape_priors, 1.0, 52)\n",
    "\n",
    "lam = []\n",
    "for i in range(len(images)):\n",
    "    u_init = pred[i][0]\n",
    "    lv_volume = subjects[i]['lv_volume'][tio.DATA][0]\n",
    "    \n",
    "    opt_params = dict(num_iter=10, err_bound=0, gamma=1e-1, steps=1e-1)\n",
    "    cmf_params = dict(u_init=u_init.cpu().to(torch.float32), par_lambda=1, par_nu=5, c_zero=0.0, c_one=0.7, b_zero=1e-1, b_one=1e1,\n",
    "                      z_i=z_i, sigma_inv=sigma_inv, L=L, V=V, sigma_ort=sigma_ort, sigma=5 * 1e-3, first_cplx=first_cplx, min_shape_face_count=min_shape_face_count, mean_shape=mean_shape, mean_shape_face=mean_shape_face)\n",
    "    \n",
    "    lam_, err_iter, num_iter = cmf_shape_prior(a_volume=lv_volume.cpu(), a_opt_params=opt_params, a_algo_params=cmf_params)\n",
    "    lam.append(lam_)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "6e68c3844f2b83c"
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Plotting the results"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "15550bf9445f3af4"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "%matplotlib notebook\n",
    "\n",
    "image_ind = 1\n",
    "tra_slice_ind = 32 # 32 stblprfdfct 30:50, 15:35 | 32 infrdfct 30:50, 10:30\n",
    "vla_slice_ind = 20 # 25 stblprfdfct 30:50, 15:35 | 20 infrdfct 30:50, 20:40\n",
    "sa_slice_ind = 40 # 40 stblprfdfct 15:35, 20:40 | 40 infrdfct 10:30, 20:40\n",
    "fig, axs = plt.subplots(1, 3)\n",
    "axs[0].imshow(images[image_ind][sa_slice_ind, :, :].cpu())\n",
    "axs[1].imshow(pred[image_ind][0, sa_slice_ind, :, :].cpu())\n",
    "axs[2].imshow(lam[image_ind][sa_slice_ind, :, :].cpu())\n",
    "plt.show()\n",
    "plt.close()"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "726073be280d152d"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# patient plotting and saving\n",
    "imgs = []\n",
    "imgs.append(images[image_ind][sa_slice_ind, :, :].cpu())\n",
    "imgs.append(pred[image_ind][0, sa_slice_ind, :, :].cpu())\n",
    "imgs.append(lam[image_ind][sa_slice_ind, :, :].cpu())\n",
    "\n",
    "labs = ['img', 'pred', 'pred_cmf']\n",
    "for i in range(len(imgs)):\n",
    "    fig = plt.imshow(imgs[i][10:30, 20:40])\n",
    "    ax = fig.axes\n",
    "    ax.spines['top'].set_visible(False)\n",
    "    ax.spines['right'].set_visible(False)\n",
    "    ax.spines['bottom'].set_visible(False)\n",
    "    ax.spines['left'].set_visible(False)\n",
    "    \n",
    "    fig.axes.get_xaxis().set_visible(False)\n",
    "    fig.axes.get_yaxis().set_visible(False)\n",
    "    \n",
    "    # plt.savefig('pat_'+ labs[i] +'_tc99_inferior_perf_defect_' + 'sa' + '.png', bbox_inches='tight', pad_inches=0)\n",
    "    #plt.close()"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "faf3e009485c05e4"
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Running CMF shape prior on labeled dataset and evaluation metrics"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "844d4fada71f5c7c"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "cmf_pred=[]\n",
    "opt_params = dict(num_iter=10, err_bound=0, gamma=1e-1, steps=1e-1)\n",
    "\n",
    "FOREGROUND = 1\n",
    "for batch_idx, batch in enumerate(tqdm(data_loader)):\n",
    "    inputs, targets = prepare_batch(batch, device)\n",
    "    with torch.no_grad():\n",
    "        probabilities = model(inputs).softmax(dim=1)[:, FOREGROUND:].cpu()\n",
    "    \n",
    "    cmf_pred = []\n",
    "    for i in range(inputs.shape[0]):\n",
    "        u_init = probabilities[i]\n",
    "        cmf_params = dict(u_init=u_init.cpu().to(torch.float32), par_lambda=1, par_nu=5, c_zero=0.0, c_one=0.7, b_zero=1e-1, b_one=1e1,\n",
    "                  z_i=z_i, sigma_inv=sigma_inv, L=L, V=V, sigma_ort=sigma_ort, sigma=5 * 1e-3, first_cplx=first_cplx, min_shape_face_count=min_shape_face_count, mean_shape=mean_shape, mean_shape_face=mean_shape_face)\n",
    "        lam_, err_iter, num_iter = cmf_shape_prior(a_volume=inputs[i, 0].cpu(), a_opt_params=opt_params, a_algo_params=cmf_params)\n",
    "        cmf_pred.append(lam_)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "cca8ea2e2ab60a83"
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Compute metric results"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "fefbfcb451a385c3"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "pred_tor = torch.zeros([len(cmf_pred), *cmf_pred[0].shape]).to(device)\n",
    "for i in range(len(cmf_pred)):\n",
    "    pred_tor[i] = cmf_pred[i].to(device)\n",
    "    \n",
    "epsilon=1e-9\n",
    "\n",
    "pred = pred_tor.argmax(dim=0)\n",
    "targ = targets[0].argmax(dim=0)\n",
    "p1 = 1 - pred\n",
    "g1 = 1 - targ\n",
    "\n",
    "tp = (targ * pred).sum(dim=(0, 1, 2))\n",
    "fp = (pred * g1).sum(dim=(0, 1, 2))\n",
    "fn = (p1 * targ).sum(dim=(0, 1, 2))\n",
    "\n",
    "precision = (tp / (tp + fp)).mean().cpu().numpy().item()\n",
    "recall = (tp / (tp + fn)).mean().cpu().numpy().item()\n",
    "iou = (tp / (tp + fp + fn)).mean().cpu().numpy().item()\n",
    "dice_score = ((2 * tp) / (2 * tp + fp + fn + epsilon)).mean().cpu().numpy().item()\n",
    "\n",
    "print(f\"Precision: {precision:.4f}\")\n",
    "print(f\"Recall: {recall:.4f}\")\n",
    "print(f\"IoU: {iou:.4f}\")\n",
    "print(f\"Dice score: {dice:.4f}\")"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "3212d2ecbd7e1c99"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
