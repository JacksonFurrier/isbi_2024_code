{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51eb4d33-824e-414e-b3b9-c537261ac00c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "from typing import Tuple\n",
    "\n",
    "import yaml\n",
    "from tqdm.notebook import tqdm\n",
    "import nrrd\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torchio as tio\n",
    "import torch\n",
    "from unet import UNet\n",
    "import point_cloud_utils as pcu\n",
    "import copy as cp\n",
    "\n",
    "from skimage.metrics import structural_similarity as ssim\n",
    "from skimage.util import montage\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "from scipy.spatial.transform import Rotation as R\n",
    "\n",
    "from src.tools.recon.projector import forward_projector, backward_projector\n",
    "from src.tools.manip.manip import normalize_volume\n",
    "\n",
    "# data fetching and handling\n",
    "from data.check_database import load_remote_data\n",
    "from data.fetch_data import fetch_data\n",
    "from src.tools.data.loadvolumes import LoadVolumes\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# CMF algorithm shape prior enhancement \n",
    "from src.algs.arm import lv_indicator\n",
    "from src.tools.cmf.cmf_shape_prior import cmf_shape_prior\n",
    "from src.tools.kde.nonlinear_shape_prior import nonlinear_shape_prior, nonlinear_shape_prior_grad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86699084",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# copied from supervised_learning.py\n",
    "\n",
    "path_experiment_conf = Path().resolve().joinpath('../../../exp/supervised_training_best.yaml')\n",
    "\n",
    "with open(path_experiment_conf, 'r') as file:\n",
    "    conf = yaml.load(file, Loader=yaml.Loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d9cadc8",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "conf"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Data fetching from remote server "
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "3de93d707dd45e52"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "dicom_loader = LoadVolumes()\n",
    "\n",
    "# initialize data fetching from remote, configuration is in data/remote.yml\n",
    "data_loaded = False\n",
    "url, datasets = load_remote_data()\n",
    "\n",
    "# read all filenames from the url\n",
    "from bs4 import BeautifulSoup\n",
    "import requests\n",
    "page = requests.get(url + '/recon/' + 'spie_2024/' + 'misc/' + 'label/')\n",
    "soup = BeautifulSoup(page.content, 'html.parser')\n",
    "label_names = []\n",
    "for label_ref in soup.find_all('a'):\n",
    "    label_names.append(label_ref.get('href'))\n",
    "\n",
    "page = requests.get(url + '/recon/' + 'spie_2024/' + 'misc/' + 'data/')\n",
    "soup = BeautifulSoup(page.content, 'html.parser')\n",
    "data_names = []\n",
    "for label_ref in soup.find_all('a'):\n",
    "    data_names.append(label_ref.get('href'))\n",
    "\n",
    "subjects = []\n",
    "subjects_data = []\n",
    "\n",
    "# fetch specific patient data\n",
    "for index in range(len(data_names)):\n",
    "\n",
    "    dicom_name = data_names[index]\n",
    "    label_name = label_names[index]\n",
    "    data_url = url + '/recon/' + 'spie_2024/' + 'misc/' + 'data/' + dicom_name\n",
    "    label_url = url + '/recon/' + 'spie_2024/' + 'misc/' + 'label/' + label_name\n",
    "    \n",
    "    # fetch the data from remote\n",
    "    data = fetch_data(data_url)\n",
    "    lab = fetch_data(label_url)\n",
    "    \n",
    "    # load data with the dicom loader\n",
    "    volume, data_loaded = dicom_loader.LoadSinglePatient(data)\n",
    "    header = nrrd.read_header(lab)\n",
    "    labels = nrrd.read_data(header, lab)\n",
    "    \n",
    "    # looks like the label export is a bit tricky so loading shall be updated\n",
    "    prob_val_1 = np.sum(np.where(np.transpose(labels, [2, 1, 0]) == 1, 1, 0))\n",
    "    prob_val_2 = np.sum(np.where(np.transpose(labels, [2, 1, 0]) == 2, 1, 0))\n",
    "    \n",
    "    if prob_val_1 > prob_val_2:\n",
    "        labels = np.where(np.transpose(labels, [2, 1, 0]) == 2, 1, 0)\n",
    "    else:\n",
    "        labels = np.where(np.transpose(labels, [2, 1, 0]) == 1, 1, 0)\n",
    "        \n",
    "    subject = tio.Subject(\n",
    "        spect=tio.ScalarImage(tensor=volume[None, ...]),\n",
    "        left_ventricle=tio.LabelMap(tensor=labels[None, ...])\n",
    "    )\n",
    "    subjects.append(subject)\n",
    "    \n",
    "    age, gender, weight, height = dicom_loader.CalculatePatientStatistics()\n",
    "    subject_data = {\n",
    "        'age' : age,\n",
    "        'gender' : gender,\n",
    "        'weight' : weight,\n",
    "        'height' : height\n",
    "    }\n",
    "    subjects_data.append(subject_data)\n",
    "\n",
    "    print(\"Volume shape: \", volume.shape, \"Labels shape:\", labels.shape)\n",
    "\n",
    "    # normalizing the frame values\n",
    "    normalize_volume(volume)\n",
    "\n",
    "assert (data_loaded)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "f5d437ca10d7d14a"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "print(url)\n",
    "print(datasets)\n",
    "print(data_url)\n",
    "print(lab)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "5a8b996075aae5a",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "%matplotlib notebook\n",
    "slice = 40\n",
    "\n",
    "fig = plt.figure()\n",
    "ax1 = fig.add_subplot(1, 3, 1)\n",
    "ax1.imshow(volume[slice, :, :])\n",
    "ax2 = fig.add_subplot(1, 3, 2)\n",
    "ax2.imshow(labels[slice, :, :])\n",
    "plt.show()"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "1766689a26a98b48",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "print(subjects[20]['spect'])"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "39d68153c275d75a",
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Load model and check devices"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "251385abbeda9040"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae223d52-65dd-4d00-a380-89d2dea79fbc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# copied from supervised_learning.py\n",
    "\n",
    "def get_model_and_optimizer(\n",
    "    config: dict,\n",
    "    device: str\n",
    ") -> Tuple[torch.nn.Module, torch.optim.Optimizer]:\n",
    "    \"\"\"\n",
    "\n",
    "    :param config:\n",
    "    :param device:\n",
    "    :return:\n",
    "    \"\"\"\n",
    "    model = UNet(\n",
    "        in_channels=1,\n",
    "        out_classes=2,\n",
    "        dimensions=3,\n",
    "        upsampling_type='linear',\n",
    "        padding=True,\n",
    "        activation='PReLU',\n",
    "        **config['model']['UNet']\n",
    "    ).to(device)\n",
    "\n",
    "    optimizer = torch.optim.AdamW(\n",
    "        model.parameters(),\n",
    "        lr=config['optimizer']['learning_rate']\n",
    "    )\n",
    "\n",
    "    return model, optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cbd513b4-9a33-45ba-bc6f-fc3209b60c91",
   "metadata": {},
   "outputs": [],
   "source": [
    "path_saved_models = Path().resolve().parent.parent.joinpath('saved_models')\n",
    "\n",
    "# supervised fine-tuning experiment name\n",
    "experiment = conf['experiment_name']\n",
    "path_weights = path_saved_models.joinpath(f\"{experiment}.pth\")\n",
    "\n",
    "weights = torch.load(path_weights)['weights']\n",
    "\n",
    "device = torch.device('cuda') if torch.cuda.is_available() else 'cpu'\n",
    "\n",
    "model, optimizer = get_model_and_optimizer(conf, device)"
   ]
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   },
   "id": "1b7cfec7b73692e7"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ac98bec-17d5-4a02-a3e1-8bd1603cfc39",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.load_state_dict(weights)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83c3ad0e-c7ac-496a-aa21-d0fe5379274d",
   "metadata": {},
   "source": [
    "# Segmentation with trained model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9ac7d10-d6c6-408a-9ab6-787d383e736c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_image(path):\n",
    "    \n",
    "    data, header = nrrd.read(path)\n",
    "    data = data.astype(np.float32)\n",
    "    affine = np.eye(4)\n",
    "    \n",
    "    return data, affine\n",
    "\n",
    "\n",
    "def prepare_batch(batch, device):\n",
    "    \n",
    "    inputs = batch['spect'][tio.DATA].to(device)\n",
    "    targets = batch['left_ventricle'][tio.DATA].to(device)\n",
    "    \n",
    "    return inputs, targets\n",
    "\n",
    "\n",
    "class Visualizer:\n",
    "    \n",
    "    def montage_nrrd(self, image):\n",
    "        if len(image.shape) > 2:\n",
    "            return montage(image)\n",
    "        else:\n",
    "            warnings.warn('Pass a 3D volume', RuntimeWarning)\n",
    "            return image\n",
    "        \n",
    "    def visualize(self, image, mask=None):\n",
    "        \n",
    "        if mask is None:\n",
    "            fig, axes = plt.subplots(1, 1, figsize=(10, 10))\n",
    "            axes.imshow(self.montage_nrrd(image))\n",
    "            axes.set_axis_off()\n",
    "        else:\n",
    "            fig, axes = plt.subplots(1, 2, figsize=(40, 40))\n",
    "        \n",
    "            for i, data in enumerate([image, mask]):\n",
    "                axes[i].imshow(self.montage_nrrd(data))\n",
    "                axes[i].set_axis_off()\n",
    " \n",
    "\n",
    "def compute_metrics(prediction, target):\n",
    "    epsilon=1e-9\n",
    "    \n",
    "    pred = prediction.argmax(dim=1)\n",
    "    targ = target.argmax(dim=1)\n",
    "    p1 = 1 - pred\n",
    "    g1 = 1 - targ\n",
    "    \n",
    "    tp = (targ * pred).sum(dim=(1, 2, 3))\n",
    "    fp = (pred * g1).sum(dim=(1, 2, 3))\n",
    "    fn = (p1 * targ).sum(dim=(1, 2, 3))\n",
    "    \n",
    "    precision = (tp / (tp + fp)).mean().cpu().numpy().item()\n",
    "    recall = (tp / (tp + fn)).mean().cpu().numpy().item()\n",
    "    iou = (tp / (tp + fp + fn)).mean().cpu().numpy().item()\n",
    "    dice_score = ((2 * tp) / (2 * tp + fp + fn + epsilon)).mean().cpu().numpy().item()\n",
    "    \n",
    "    return precision, recall, iou, dice_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0b948ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "# subjects = []\n",
    "target_shape = (128, 128, 128)\n",
    "\n",
    "transform_pipeline = tio.Compose([\n",
    "    tio.Resample(subjects[20]['spect']),\n",
    "    tio.ToCanonical(),\n",
    "    #tio.CropOrPad(target_shape=target_shape, mask_name=\"left_ventricle\"),\n",
    "    tio.ZNormalization(),\n",
    "    tio.OneHot()\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11ffb4ba-0ecb-42cc-99d9-64ec1ad29d36",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = tio.SubjectsDataset(subjects, transform=transform_pipeline)\n",
    "print(f\"Dataset size: {len(dataset)} subjects\")\n",
    "\n",
    "data_loader = torch.utils.data.DataLoader(\n",
    "    dataset,\n",
    "    batch_size=1,\n",
    "    shuffle=False,\n",
    "    num_workers=0,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d9d5cd8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_specificity_recall_precision(label_np, pred_np):\n",
    "    label_flat = label_np.flatten()\n",
    "    pred_flat = (pred_np > 0.5).astype(int).flatten()\n",
    "    tn, fp, fn, tp = confusion_matrix(label_flat, pred_flat).ravel()\n",
    "    specificity = tn / (tn + fp)\n",
    "    recall = tp / (tp + fn)\n",
    "    precision = tp / (tp + fp)\n",
    "    return specificity, recall, precision"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e79c57c-4008-4218-abba-8f5d02509dff",
   "metadata": {},
   "outputs": [],
   "source": [
    "FOREGROUND = 1\n",
    "vis = Visualizer()\n",
    "\n",
    "model.eval()\n",
    "\n",
    "num_samples = 0\n",
    "specificity_list = []\n",
    "recall_list = []\n",
    "precision_list = []\n",
    "\n",
    "\n",
    "for batch_idx, batch in enumerate(tqdm(data_loader)):\n",
    "\n",
    "    inputs, targets = prepare_batch(batch, device)\n",
    "    \n",
    "    with torch.no_grad():\n",
    "\n",
    "        predictions = model(inputs).softmax(dim=1)\n",
    "        probabilities = predictions[:, FOREGROUND:].cpu()\n",
    "    \n",
    "\n",
    "    for i in range(len(batch['spect'][tio.DATA])):\n",
    "    \n",
    "        spect = batch['spect'][tio.DATA][i].permute(3, 0, 1, 2)\n",
    "        label = batch['left_ventricle'][tio.DATA][i][1:, ...].permute(3, 0, 1, 2)\n",
    "        pred = probabilities[i].permute(3, 0, 1, 2)\n",
    "        \n",
    "        # vis.visualize(\n",
    "        #     np.squeeze(label.permute(1,0,2,3).numpy(), axis=0),\n",
    "        #     np.squeeze(pred.permute(1,0,2,3).numpy(), axis=0)\n",
    "        # )\n",
    "        \n",
    "        label_np = label.squeeze().permute(1, 2, 0).numpy()\n",
    "        pred_np = pred.squeeze().permute(1, 2, 0).numpy()\n",
    "        \n",
    "        num_samples += 1\n",
    "        \n",
    "        specificity, recall, precision = calculate_specificity_recall_precision(label_np, pred_np)\n",
    "        specificity_list.append(1 - specificity)\n",
    "        recall_list.append(recall)\n",
    "        precision_list.append(precision)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37c966b1-142f-4b23-85af-aa2f4881c782",
   "metadata": {},
   "outputs": [],
   "source": [
    "precision, recall, iou, dice = compute_metrics(predictions, targets)\n",
    "\n",
    "print(f\"Precision: {precision:.4f}\")\n",
    "print(f\"Recall: {recall:.4f}\")\n",
    "print(f\"IoU: {iou:.4f}\")\n",
    "print(f\"Dice score: {dice:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "predictions.shape"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "554a467dd123158a"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "pred = predictions.argmax(dim=1) # predictions\n",
    "target = targets.argmax(dim=1) # labels\n",
    "lv_spect = batch['spect'][tio.DATA][0]\n",
    "%matplotlib notebook\n",
    "plt.imshow(lv_spect[0, :, :, 16].cpu().numpy())"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "7bd4623809e1bf88"
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Running shape prior enhanced CMF on predictions"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "12c59e39b0a4c266"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "lv_volume = np.zeros([64, 64, 64])\n",
    "\n",
    "num_prior = 9\n",
    "shape_priors = np.zeros([num_prior, *lv_volume.shape])\n",
    "\n",
    "wall_thickness = np.random.uniform(0.3, 1.0, num_prior)\n",
    "rot_angles = np.random.uniform(0, 2 * np.pi, num_prior)\n",
    "curvature = np.random.uniform(1.5, 3, num_prior)\n",
    "sigmas = np.random.uniform(-0.5, -1, num_prior)\n",
    "\n",
    "for i in range(num_prior):\n",
    "    volume = np.zeros([*lv_volume.shape])\n",
    "    params = dict(a=wall_thickness[i], c=curvature[i], sigma=sigmas[i])\n",
    "    rot_mx = R.from_quat([0, 0, np.sin(rot_angles[i]), np.cos(rot_angles[i])])\n",
    "\n",
    "    transform_params = [np.eye(3, 3), [16, 16, 0], 1.5]\n",
    "    shape_priors[i] = lv_indicator(volume, params, transform_params, a_plot=False)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "51bebdd8dfc2ec53"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# u_init = pred[0]\n",
    "# lv_volume = lv_spect[0]\n",
    "# \n",
    "# sigma_inv, mean_shape, dec_faces = nonlinear_shape_prior(shape_priors, 1.0, 52)\n",
    "# \n",
    "# opt_params = dict(num_iter=4, err_bound=0, gamma=1e-1, steps=1e-1)\n",
    "# cmf_params = dict(par_lambda=10, u_init=u_init.cpu().to(torch.float32) ,par_nu=1, c_zero=0.1, c_one=0.8, b_zero=0.1, b_one=0.7, sigma_inv=sigma_inv, mean_shape=mean_shape, faces=dec_faces)\n",
    "# lam, err_iter, num_iter = cmf_shape_prior(a_volume=lv_volume.cpu(), a_opt_params=opt_params, a_algo_params=cmf_params)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "916d0b5d22399497"
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Running CMF shape prior on hypoperfused hearts"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "31a779d366a106bf"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "path_images = [\n",
    "    \"/home/jackson/GIT/ELTE/papers/left_ventricle_segmentation/data/tc99_female_no_defect.nrrd\",\n",
    "    \"/home/jackson/GIT/ELTE/papers/left_ventricle_segmentation/data/tc99_inferior_perf_defect.nrrd\",\n",
    "    \"/home/jackson/GIT/ELTE/papers/left_ventricle_segmentation/data/tc99m_reversible_defect.nrrd\",\n",
    "    \"/home/jackson/GIT/ELTE/papers/left_ventricle_segmentation/data/tc99m_stable_perfusion_defect.nrrd\"\n",
    "]\n",
    "\n",
    "images = []\n",
    "\n",
    "# load images from local folder\n",
    "for path in path_images:\n",
    "    img, _ = load_image(path)\n",
    "    images.append(torch.from_numpy(img).to(device))\n",
    "\n",
    "# running the network on ill conditioned patients\n",
    "pred = []\n",
    "\n",
    "target_shape = (64, 64, 64)\n",
    "transform = tio.Compose([\n",
    "    tio.CropOrPad(target_shape=target_shape),\n",
    "    tio.ZNormalization(),\n",
    "    tio.OneHot()\n",
    "])\n",
    "\n",
    "subjects = []\n",
    "\n",
    "for path in path_images:\n",
    "    with torch.no_grad():\n",
    "        subject = tio.Subject(\n",
    "            lv_volume = tio.ScalarImage(path),\n",
    "            reader=load_image\n",
    "        )\n",
    "        subject.load()\n",
    "        transformed = transform(subject)\n",
    "        subjects.append(transformed)\n",
    "        \n",
    "        img_pred = model(transformed['lv_volume'][tio.DATA][None, ...].to(device)).softmax(dim=1)[:, FOREGROUND].cpu() # for debugging purpose\n",
    "        pred.append(img_pred)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "56e912ef2c519754"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# run shape prior based CMF enhancement on predictions\n",
    "z_i, sigma_inv, L, V, sigma_ort, sigma, first_cplx, min_shape_face_count, mean_shape, mean_shape_face  = nonlinear_shape_prior(shape_priors, 1.0, 52)\n",
    "\n",
    "lam = []\n",
    "for i in range(len(images)):\n",
    "    u_init = pred[i][0]\n",
    "    lv_volume = subjects[i]['lv_volume'][tio.DATA][0]\n",
    "    \n",
    "    opt_params = dict(num_iter=10, err_bound=0, gamma=1e-1, steps=1e-1)\n",
    "    cmf_params = dict(u_init=u_init.cpu().to(torch.float32), par_lambda=1, par_nu=5, c_zero=0.0, c_one=0.7, b_zero=1e-1, b_one=1e1,\n",
    "                      z_i=z_i, sigma_inv=sigma_inv, L=L, V=V, sigma_ort=sigma_ort, sigma=5 * 1e-3, first_cplx=first_cplx, min_shape_face_count=min_shape_face_count, mean_shape=mean_shape, mean_shape_face=mean_shape_face)\n",
    "    \n",
    "    lam_, err_iter, num_iter = cmf_shape_prior(a_volume=lv_volume.cpu(), a_opt_params=opt_params, a_algo_params=cmf_params)\n",
    "    lam.append(lam_)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "6e68c3844f2b83c"
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Plotting the results"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "15550bf9445f3af4"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "%matplotlib notebook\n",
    "\n",
    "image_ind = 1\n",
    "tra_slice_ind = 32 # 32 stblprfdfct 30:50, 15:35 | 32 infrdfct 30:50, 10:30\n",
    "vla_slice_ind = 20 # 25 stblprfdfct 30:50, 15:35 | 20 infrdfct 30:50, 20:40\n",
    "sa_slice_ind = 40 # 40 stblprfdfct 15:35, 20:40 | 40 infrdfct 10:30, 20:40\n",
    "fig, axs = plt.subplots(1, 3)\n",
    "axs[0].imshow(images[image_ind][sa_slice_ind, :, :].cpu())\n",
    "axs[1].imshow(pred[image_ind][0, sa_slice_ind, :, :].cpu())\n",
    "axs[2].imshow(lam[image_ind][sa_slice_ind, :, :].cpu())\n",
    "plt.show()\n",
    "plt.close()"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "726073be280d152d"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# patient plotting and saving\n",
    "imgs = []\n",
    "imgs.append(images[image_ind][sa_slice_ind, :, :].cpu())\n",
    "imgs.append(pred[image_ind][0, sa_slice_ind, :, :].cpu())\n",
    "imgs.append(lam[image_ind][sa_slice_ind, :, :].cpu())\n",
    "\n",
    "labs = ['img', 'pred', 'pred_cmf']\n",
    "for i in range(len(imgs)):\n",
    "    fig = plt.imshow(imgs[i][10:30, 20:40])\n",
    "    ax = fig.axes\n",
    "    ax.spines['top'].set_visible(False)\n",
    "    ax.spines['right'].set_visible(False)\n",
    "    ax.spines['bottom'].set_visible(False)\n",
    "    ax.spines['left'].set_visible(False)\n",
    "    \n",
    "    fig.axes.get_xaxis().set_visible(False)\n",
    "    fig.axes.get_yaxis().set_visible(False)\n",
    "    \n",
    "    # plt.savefig('pat_'+ labs[i] +'_tc99_inferior_perf_defect_' + 'sa' + '.png', bbox_inches='tight', pad_inches=0)\n",
    "    #plt.close()"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "faf3e009485c05e4"
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Running CMF shape prior on labeled dataset and evaluation metrics"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "844d4fada71f5c7c"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "from geomloss import SamplesLoss\n",
    "eps = 5 * 1e-3\n",
    "loss_unbalanced = SamplesLoss(loss='sinkhorn', p=2, blur=eps, scaling=0.95)\n",
    "sigma = 5 * 1e0\n",
    "\n",
    "k = lambda x, y, sigma : torch.exp(-sigma * loss_unbalanced(x, y))\n",
    "centering_point = np.array([0.45, 0.45, 0.45])\n",
    "\n",
    "z_i, sigma_inv, L, V, sigma_ort, sigma, first_cplx, min_shape_face_count, mean_shape, mean_shape_face, k_matrix_sum, k_matrix  = nonlinear_shape_prior(shape_priors, kernel=k, sigma=sigma, centering_point=centering_point)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "2f359773bf50ee4f"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "cmf_pred=[]\n",
    "opt_params = dict(num_iter=10, err_bound=0, gamma=1e-1, steps=1e-1)\n",
    "\n",
    "FOREGROUND = 1\n",
    "for batch_idx, batch in enumerate(tqdm(data_loader)):\n",
    "    inputs, targets = prepare_batch(batch, device)\n",
    "    with torch.no_grad():\n",
    "        probabilities = model(inputs).softmax(dim=1)[:, FOREGROUND:].cpu()\n",
    "    \n",
    "    cmf_pred = []\n",
    "    for i in range(inputs.shape[0]):\n",
    "        u_init = probabilities[i]        \n",
    "        lv_volume = subjects[i, 0]\n",
    "    \n",
    "        opt_params = dict(num_iter=14, err_bound=0, gamma=1e-2, steps=1e-1)\n",
    "        cmf_params = dict(u_init=u_init.cpu().to(torch.float32), par_lambda=1.0, par_nu=0.7, c_zero=0.4, c_one=0.5, b_zero=1e-1, b_one=1e1,\n",
    "                          z_i=z_i, sigma_inv=sigma_inv, L=L, V=V, sigma_ort=sigma_ort, sigma=sigma, first_cplx=first_cplx, min_shape_face_count=min_shape_face_count, mean_shape=mean_shape, mean_shape_face=mean_shape_face, k_matrix_sum=k_matrix_sum, k_matrix=k_matrix, kernel=k)\n",
    "        lam, err_iter, num_iter, lam_shape_prior = cmf_shape_prior(a_volume=torch.from_numpy(lv_volume), a_opt_params=opt_params, a_algo_params=cmf_params)\n",
    "        \n",
    "        # fill\n",
    "        fill_value = 2\n",
    "        label_prior = cp.copy(lam_shape_prior)\n",
    "        filled_myocard = pcu.flood_fill_3d(label_prior, [0, 0, 0], fill_value)\n",
    "        filled_myocard = np.where( filled_myocard <= 1, 1, 0)\n",
    "        pred_myocard = np.where( filled_myocard == 1, lam, 0)\n",
    "    \n",
    "        cmf_pred.append(filled_myocard)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "cca8ea2e2ab60a83"
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Compute metric results"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "fefbfcb451a385c3"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "pred_tor = torch.zeros([len(cmf_pred), *cmf_pred[0].shape]).to(device)\n",
    "for i in range(len(cmf_pred)):\n",
    "    pred_tor[i] = cmf_pred[i].to(device)\n",
    "    \n",
    "epsilon=1e-9\n",
    "\n",
    "pred = pred_tor.argmax(dim=0)\n",
    "targ = targets[0].argmax(dim=0)\n",
    "p1 = 1 - pred\n",
    "g1 = 1 - targ\n",
    "\n",
    "tp = (targ * pred).sum(dim=(0, 1, 2))\n",
    "fp = (pred * g1).sum(dim=(0, 1, 2))\n",
    "fn = (p1 * targ).sum(dim=(0, 1, 2))\n",
    "\n",
    "precision = (tp / (tp + fp)).mean().cpu().numpy().item()\n",
    "recall = (tp / (tp + fn)).mean().cpu().numpy().item()\n",
    "iou = (tp / (tp + fp + fn)).mean().cpu().numpy().item()\n",
    "dice_score = ((2 * tp) / (2 * tp + fp + fn + epsilon)).mean().cpu().numpy().item()\n",
    "\n",
    "print(f\"Precision: {precision:.4f}\")\n",
    "print(f\"Recall: {recall:.4f}\")\n",
    "print(f\"IoU: {iou:.4f}\")\n",
    "print(f\"Dice score: {dice:.4f}\")"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "3212d2ecbd7e1c99"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
